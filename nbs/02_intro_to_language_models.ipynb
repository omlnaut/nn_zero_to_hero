{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19f72cf-8e59-4264-96b0-946053cef7dc",
   "metadata": {},
   "source": [
    "# The spelled-out intro to language modeling: building makemore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c69cb-854d-4c19-b237-b5ba194a4591",
   "metadata": {},
   "source": [
    "Following: https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a512cfd5-1a33-4f3d-92fe-433b57d50f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0d6571-963f-4cd1-8bc4-566c2d07a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d69bd-2701-4f63-a922-8f27d9d98dca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Exploring bigrams (0:00 - 0:15:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71232cb1-ecf2-46b6-b36e-5b4eaa751075",
   "metadata": {},
   "source": [
    "Tasks done in the video:\n",
    "- Load the dataset\n",
    "- Explore\n",
    "    - min/max length of names\n",
    "    - number of names\n",
    "- count all the bigrams into a dictionary\n",
    "    - dedicated \\<S\\> and \\<E\\> tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813b672a-fd7b-43fe-b5c6-864fc318b781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = (data/'names.txt').open().read().splitlines()\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec49eac-8297-4e3c-9797-1b07eeb3adce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e02d0830-5e4f-4e57-959d-a70e0cdaa225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(name) for name in names), max(len(name) for name in names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce29c4b-f415-4d3e-917d-ad5492b732f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = defaultdict(int)\n",
    "start = '<S>'\n",
    "end = '<E>'\n",
    "\n",
    "for name in names:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        bigrams[(ch1,ch2)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e00e97-cf84-4882-8a64-6aef06f796ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '<E>'), 6763),\n",
       " (('a', '<E>'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('<S>', 'a'), 4410),\n",
       " (('e', '<E>'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('<S>', 'k'), 2963)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((bigram_tuples for bigram_tuples in bigrams.items()), key=lambda b: b[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a061496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58c250c6-d481-4889-b5c6-276218446e3b",
   "metadata": {},
   "source": [
    "# Bigrams into torch.Tensor ( - 00:36:00, skipping efficiency until 00:50:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb66ea-8792-43e7-b979-d973267e1fe1",
   "metadata": {},
   "source": [
    "- Goal: n*n matrix that holds the bigram count in each cell\n",
    "- No more dedicated start/stopping tokens, instead use . for both\n",
    "- sample from the model\n",
    "    - start with the starting dot\n",
    "    - choose random next character according to probabilities in that row (torch.multinomial)\n",
    "    - repeat until ending-dot is reached\n",
    "    - Use torch.Generator for comparability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1b3ce-ef5d-4ae7-a5f5-fb1dc9948c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bigrams to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd60e0bb-ea36-4d0f-a5e9-f58f523ba331",
   "metadata": {},
   "source": [
    "Extracting all used characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554df160-1fb3-4b68-9ae9-3d616f74374e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = set('.')\n",
    "characters = characters.union(set(''.join(names)))\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae5f08b-d19e-462e-9c32-8cef882d03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "563dd508-65ad-4544-89c2-4f8136cc2419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 0,\n",
       " '.': 1,\n",
       " 'h': 2,\n",
       " 'x': 3,\n",
       " 'u': 4,\n",
       " 'f': 5,\n",
       " 'c': 6,\n",
       " 's': 7,\n",
       " 'k': 8,\n",
       " 'g': 9,\n",
       " 'd': 10,\n",
       " 'r': 11,\n",
       " 'i': 12,\n",
       " 'e': 13,\n",
       " 't': 14,\n",
       " 'b': 15,\n",
       " 'm': 16,\n",
       " 'p': 17,\n",
       " 'l': 18,\n",
       " 'w': 19,\n",
       " 'z': 20,\n",
       " 'a': 21,\n",
       " 'v': 22,\n",
       " 'q': 23,\n",
       " 'o': 24,\n",
       " 'j': 25,\n",
       " 'y': 26}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {char: i for i,char in enumerate(characters)}\n",
    "itos = {i: char for char,i in stoi.items()}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b31e1b-f04b-4c0d-96cd-1eef0ea5a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = torch.zeros((len(characters), len(characters)))\n",
    "start = '.'\n",
    "end = '.'\n",
    "\n",
    "for name in names:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        bigrams[row_index, col_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219d08e-c726-47c8-a88a-e6090fbb1704",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911228de-7e7d-4bb6-b260-a2df6548e9f1",
   "metadata": {},
   "source": [
    "Counts for characters following the start character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f3a711c-c41d-4dfb-a518-05d4fb92edb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1146.,    0.,  874.,  134.,   78.,  417., 1542., 2055., 2963.,  669.,\n",
       "        1690., 1639.,  591., 1531., 1308., 1306., 2538.,  515., 1572.,  307.,\n",
       "         929., 4410.,  376.,   92.,  394., 2422.,  535.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[stoi[start],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a141f0-695a-4cb6-87a6-003b36f72927",
   "metadata": {},
   "source": [
    "Drawing a sample with counts as weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77339bbd-9233-493f-98ca-3d9db16efaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_idx = torch.multinomial(bigrams[stoi[start],:], 1, replacement=True).item()\n",
    "next_char = itos[next_idx]\n",
    "next_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7e4cb-fc64-4ee0-861d-ee7628835f50",
   "metadata": {},
   "source": [
    "Repeat until the stopping token is drawn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a236d426-4aff-4062-8882-da71aeb9ccc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".lor.\n",
      ".xow.\n",
      ".ppteorvayisangahelika.\n",
      ".dr.\n",
      ".lbequmynarinth.\n",
      ".ahlikrishachridatacosstrisolel.\n",
      ".rghan.\n",
      ".keryan.\n",
      ".bre.\n",
      ".mahaixxtahan.\n",
      ".kh.\n",
      ".h.\n",
      ".eleeerh.\n",
      ".jaaluirielaban.\n",
      ".y.\n",
      ".ko.\n",
      ".aierstheayaholaikiemaie.\n",
      ".jamah.\n",
      ".ba.\n",
      ".dawisilayvelonalari.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    name = start\n",
    "    while True:\n",
    "        next_idx = torch.multinomial(bigrams[stoi[name[-1]],:], 1, replacement=True, generator=g).item()\n",
    "        next_char = itos[next_idx]\n",
    "        name += next_char\n",
    "\n",
    "        if next_char == end:\n",
    "            break\n",
    "\n",
    "\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a77b4-f1ca-4bf4-95e1-88d9b6b2c65b",
   "metadata": {},
   "source": [
    "Sanity-Check: Drawing with uniform probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09bc386-e3b6-4abe-8ab4-e6bc7d110798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".pvw.\n",
      "..\n",
      ".johplpejpqaytgv.\n",
      ".tarbzudvukunptbjezyuapr.\n",
      ".zufzrmcdusgsvifdcrlwpiqtglskkyqianguxonxfreyaxdtdbfbvdvlsspldlnxchk.\n",
      ".hrwimbrxnozoqhmertaawousycfokqpmiumutqyvrjowpdcblppmcowzqrcbackvqckewajjbzvxvvpmcxhjudxbakr.\n",
      ".drkpttmpeeii.\n",
      ".blupjnswymqnyisgdgt.\n",
      ".tsyyaaiwjvplaca.\n",
      ".q.\n",
      ".vwuhtqvieljmvslwcsmwksteq.\n",
      ".cpewduvhktsvbggsokrquizlurqt.\n",
      ".syjrtpvnicwzupgsvtxubgufzwarsumnxcmdwofpdxwedqsayfwnqbcicdocijishfsmdumbvuzqnuiyjwpzlhkokxutfgaaenozjwiche.\n",
      ".hb.\n",
      "..\n",
      ".tjdmbdaadcixw.\n",
      ".axpxszdeiypzh.\n",
      ".gwvolzsamrmmgsoaufduywlbpfgsbvaoevzndiocbirbyxgnzrkugvrugc.\n",
      ".oxfvimrzrqqvaoijezqjismy.\n",
      ".aquvocvhbbciuumkedfbedsdxpfpqznnqioxixdhenpaajgdztyejxwkxibledjlflpwibeulihaqptiegzhlepkzhuqhjviweqthblqxukdbzfyqtwoavccvgtlefufiahkucsz.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "weights = torch.ones(len(characters))\n",
    "\n",
    "for i in range(20):\n",
    "    name = start\n",
    "    while True:\n",
    "        next_idx = torch.multinomial(weights, 1, replacement=True, generator=g).item()\n",
    "        next_char = itos[next_idx]\n",
    "        name += next_char\n",
    "\n",
    "        if next_char == end:\n",
    "            break\n",
    "\n",
    "\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c9bed-8748-482c-b958-9aef3999a7c8",
   "metadata": {},
   "source": [
    "# Loss function ( - 01:03:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8711cb9-5fd5-429d-9a59-fd2778a56b44",
   "metadata": {},
   "source": [
    "- negative Likelihood is used to measure loss (product of probabilities)\n",
    "- use logs for numerical purposes (turns into the sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae0f8860-3d79-4b58-b90b-5c32b4ed7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = bigrams / bigrams.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b68377e6-902b-4da7-a1ab-e1bd07a116b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(., e): -3.0408453941345215\n",
      "(e, m): -3.2793259620666504\n",
      "(m, m): -3.6772043704986572\n",
      "(m, a): -0.9417552351951599\n",
      "(a, .): -1.6298604011535645\n",
      "Neg. Log-Likelihood: 12.568990707397461\n",
      "Mean Neg. Log-Likelihood: 2.513798236846924\n",
      "\n",
      "(., o): -4.3981709480285645\n",
      "(o, l): -2.550807476043701\n",
      "(l, i): -1.7277942895889282\n",
      "(i, v): -4.186665058135986\n",
      "(v, i): -1.0382850170135498\n",
      "(i, a): -1.9795759916305542\n",
      "(a, .): -1.6298604011535645\n",
      "Neg. Log-Likelihood: 17.511159896850586\n",
      "Mean Neg. Log-Likelihood: 2.501594305038452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in names[:2]:\n",
    "    name = [start] + list(name) + [end]\n",
    "    log_likelihood = 0\n",
    "    n = 0\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        prob = P[row_index, col_index]\n",
    "        log = torch.log(prob)\n",
    "        log_likelihood += log\n",
    "        n += 1\n",
    "        \n",
    "        print(f'({ch1}, {ch2}): {log}')\n",
    "    print(f'Neg. Log-Likelihood: {-log_likelihood}')\n",
    "    print(f'Mean Neg. Log-Likelihood: {-log_likelihood / n}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcfb9010-b329-4821-b8cf-67f931aefbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(., a): -1.9828919172286987\n",
      "(a, n): -1.8295611143112183\n",
      "(n, d): -3.259352207183838\n",
      "(d, r): -2.562042474746704\n",
      "(r, e): -2.012739896774292\n",
      "(e, j): -5.917083740234375\n",
      "(j, .): -3.7097861766815186\n",
      "Neg. Log-Likelihood: 21.273456573486328\n",
      "Mean Neg. Log-Likelihood: 3.03906512260437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in ['andrej']:\n",
    "    name = [start] + list(name) + [end]\n",
    "    log_likelihood = 0\n",
    "    n = 0\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        prob = P[row_index, col_index]\n",
    "        log = torch.log(prob)\n",
    "        log_likelihood += log\n",
    "        n += 1\n",
    "        \n",
    "        print(f'({ch1}, {ch2}): {log}')\n",
    "    print(f'Neg. Log-Likelihood: {-log_likelihood}')\n",
    "    print(f'Mean Neg. Log-Likelihood: {-log_likelihood / n}')\n",
    "    print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c9db0de-d554-4371-802b-73dde5119e3f",
   "metadata": {},
   "source": [
    "# Neural Network Approach ( - 01:25:00)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0e1b4c5-b87a-4741-9058-d38e4b577c84",
   "metadata": {},
   "source": [
    "- create training set\n",
    "    - x tensor with first letter\n",
    "    - y tensor with second letter\n",
    "- use one-hot encoding to feed indices into nn\n",
    "- \"nn\" is for now just a weight matrix and bias vector with grads\n",
    "- output should be 27 dimensional\n",
    "    - turn into \"probabilities\" by softmax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a314c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = torch.zeros((len(characters), len(characters)))\n",
    "start = '.'\n",
    "end = '.'\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for name in names[:1]:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        xs.append(row_index)\n",
    "        ys.append(col_index)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66debec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "W = torch.rand(size=(27,27), requires_grad=True, generator=g)\n",
    "b = torch.rand(size=(1,27), requires_grad=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "463af69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8610746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f5bc2574c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAACHCAYAAABK4hAcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANwklEQVR4nO3df2iV5cPH8c82t+OPjkfn2o/T5pxaSs1NUrfEJxM2nBaS6R9W/rGGGNWZOEclC3QJwcIgpJKMoPzHXwktSR4MWW4SzB9MxITao0PwyNyWgmc6c66d6/mjr+d5jj+mZ7t27p3j+wU37Nzn4r4/XF7ix/vcO3eCMcYIAADAgkSnAwAAgPhBsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANaOiebJgMKj29na53W4lJCRE89QAAGCQjDG6fv26vF6vEhMHviYR1WLR3t6unJycaJ4SAABY4vf7lZ2dPeCYqBYLt9stSfovvaxRSh7Sser/53cbkSRJrz0zy9qxAACIN/+oT7/pv0P/jg8kqsXizscfo5SsUQlDKxbj3fZuDxlqFgAA4tp/Hv7xKLcxcPMmAACwhmIBAACsoVgAAABrBlUstm/frilTpmj06NEqLi7WiRMnbOcCAAAxKOJisW/fPlVXV6u2tlanTp1SYWGhysrK1NXVNRz5AABADIm4WHz++edau3atKioq9Oyzz2rHjh0aO3asvvvuu+HIBwAAYkhExeL27dtqaWlRaWnp/x0gMVGlpaVqbm6+Z3xvb6+6u7vDNgAAEL8iKhZXrlxRf3+/MjIywvZnZGSoo6PjnvF1dXXyeDyhjW/dBAAgvg3rb4XU1NQoEAiENr/fP5ynAwAADovomzfT0tKUlJSkzs7OsP2dnZ3KzMy8Z7zL5ZLL5RpaQgAAEDMiumKRkpKiOXPmqKGhIbQvGAyqoaFB8+fPtx4OAADEloifFVJdXa3y8nLNnTtXRUVF2rZtm3p6elRRUTEc+QAAQAyJuFisWrVKf/31lzZv3qyOjg7Nnj1bhw4duueGTgAA8PgZ1NNNKysrVVlZaTsLAACIcTwrBAAAWDOoKxYjQZl3ttMRgMfKL+2nrRyHv7tAfOOKBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALCGYgEAAKyhWAAAAGsoFgAAwBqKBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACwhmIBAACsGeV0AACxocw72+kIw+aX9tNWjhPPcwQ8Kq5YAAAAaygWAADAGooFAACwhmIBAACsiahY1NXVad68eXK73UpPT9fy5cvV2to6XNkAAECMiahYNDU1yefz6dixYzp8+LD6+vq0ePFi9fT0DFc+AAAQQyL6ddNDhw6Fvd65c6fS09PV0tKihQsXWg0GAABiz5C+xyIQCEiSUlNT7/t+b2+vent7Q6+7u7uHcjoAADDCDfrmzWAwqKqqKi1YsED5+fn3HVNXVyePxxPacnJyBh0UAACMfIMuFj6fT2fPntXevXsfOKampkaBQCC0+f3+wZ4OAADEgEF9FFJZWamDBw/q6NGjys7OfuA4l8sll8s16HAAACC2RFQsjDFat26d6uvr1djYqLy8vOHKBQAAYlBExcLn82n37t06cOCA3G63Ojo6JEkej0djxowZloAAACB2RHSPxddff61AIKBFixYpKysrtO3bt2+48gEAgBgS8UchAAAAD8KzQgAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1o5wOAABOK/POdjrCY+WX9tNWjsOf28jEFQsAAGANxQIAAFhDsQAAANZQLAAAgDVDKhaffvqpEhISVFVVZSkOAACIZYMuFidPntQ333yjgoICm3kAAEAMG1SxuHHjhlavXq1vv/1WEydOtJ0JAADEqEEVC5/Pp1deeUWlpaUDjuvt7VV3d3fYBgAA4lfEX5C1d+9enTp1SidPnnzo2Lq6Om3ZsmVQwQAAQOyJ6IqF3+/X+vXrtWvXLo0ePfqh42tqahQIBEKb3+8fdFAAADDyRXTFoqWlRV1dXXr++edD+/r7+3X06FF99dVX6u3tVVJSUug9l8sll8tlLy0AABjRIioWJSUl+v3338P2VVRUaObMmdq4cWNYqQAAAI+fiIqF2+1Wfn5+2L5x48Zp0qRJ9+wHAACPH755EwAAWDPkx6Y3NjZaiAEAAOIBVywAAIA1Q75iEQljjCTpH/VJJppnBgCMFN3Xg1aO84/ps3IcPNw/+neu7/w7PpAE8yijLLl06ZJycnKidToAAGCR3+9Xdnb2gGOiWiyCwaDa29vldruVkJDwwHHd3d3KycmR3+/X+PHjoxXvscV8Rw9zHV3Md3Qx39EVzfk2xuj69evyer1KTBz4LoqofhSSmJj40Kbz/40fP57FGUXMd/Qw19HFfEcX8x1d0Zpvj8fzSOO4eRMAAFhDsQAAANaMyGLhcrlUW1vLc0aihPmOHuY6upjv6GK+o2ukzndUb94EAADxbUResQAAALGJYgEAAKyhWAAAAGsoFgAAwBqKBQAAsGbEFYvt27drypQpGj16tIqLi3XixAmnI8Wljz/+WAkJCWHbzJkznY4VN44ePaply5bJ6/UqISFBP/30U9j7xhht3rxZWVlZGjNmjEpLS3Xu3DlnwsaBh833W2+9dc96X7JkiTNhY1xdXZ3mzZsnt9ut9PR0LV++XK2trWFjbt26JZ/Pp0mTJumJJ57QypUr1dnZ6VDi2PYo871o0aJ71vc777zjUOIRViz27dun6upq1dbW6tSpUyosLFRZWZm6urqcjhaXnnvuOV2+fDm0/fbbb05Hihs9PT0qLCzU9u3b7/v+1q1b9cUXX2jHjh06fvy4xo0bp7KyMt26dSvKSePDw+ZbkpYsWRK23vfs2RPFhPGjqalJPp9Px44d0+HDh9XX16fFixerp6cnNGbDhg36+eeftX//fjU1Nam9vV0rVqxwMHXsepT5lqS1a9eGre+tW7c6lFiSGUGKioqMz+cLve7v7zder9fU1dU5mCo+1dbWmsLCQqdjPBYkmfr6+tDrYDBoMjMzzWeffRbad+3aNeNyucyePXscSBhf7p5vY4wpLy83r776qiN54l1XV5eRZJqamowx/67l5ORks3///tCYP/74w0gyzc3NTsWMG3fPtzHGvPTSS2b9+vXOhbrLiLlicfv2bbW0tKi0tDS0LzExUaWlpWpubnYwWfw6d+6cvF6vpk6dqtWrV+vixYtOR3osXLhwQR0dHWFr3ePxqLi4mLU+jBobG5Wenq4ZM2bo3Xff1dWrV52OFBcCgYAkKTU1VZLU0tKivr6+sPU9c+ZMTZ48mfVtwd3zfceuXbuUlpam/Px81dTU6ObNm07EkxTlp5sO5MqVK+rv71dGRkbY/oyMDP35558OpYpfxcXF2rlzp2bMmKHLly9ry5YtevHFF3X27Fm53W6n48W1jo4OSbrvWr/zHuxasmSJVqxYoby8PLW1temjjz7S0qVL1dzcrKSkJKfjxaxgMKiqqiotWLBA+fn5kv5d3ykpKZowYULYWNb30N1vviXpzTffVG5urrxer86cOaONGzeqtbVVP/74oyM5R0yxQHQtXbo09HNBQYGKi4uVm5urH374QWvWrHEwGWDf66+/Hvp51qxZKigo0LRp09TY2KiSkhIHk8U2n8+ns2fPcn9WlDxovt9+++3Qz7NmzVJWVpZKSkrU1tamadOmRTvmyLl5My0tTUlJSffcOdzZ2anMzEyHUj0+JkyYoGeeeUbnz593Okrcu7OeWevOmTp1qtLS0ljvQ1BZWamDBw/qyJEjys7ODu3PzMzU7du3de3atbDxrO+hedB8309xcbEkOba+R0yxSElJ0Zw5c9TQ0BDaFwwG1dDQoPnz5zuY7PFw48YNtbW1KSsry+kocS8vL0+ZmZlha727u1vHjx9nrUfJpUuXdPXqVdb7IBhjVFlZqfr6ev3666/Ky8sLe3/OnDlKTk4OW9+tra26ePEi63sQHjbf93P69GlJcmx9j6iPQqqrq1VeXq65c+eqqKhI27ZtU09PjyoqKpyOFnfef/99LVu2TLm5uWpvb1dtba2SkpL0xhtvOB0tLty4cSPsfwsXLlzQ6dOnlZqaqsmTJ6uqqkqffPKJnn76aeXl5WnTpk3yer1avny5c6Fj2EDznZqaqi1btmjlypXKzMxUW1ubPvzwQ02fPl1lZWUOpo5NPp9Pu3fv1oEDB+R2u0P3TXg8Ho0ZM0Yej0dr1qxRdXW1UlNTNX78eK1bt07z58/XCy+84HD62POw+W5ra9Pu3bv18ssva9KkSTpz5ow2bNighQsXqqCgwJnQTv9ayt2+/PJLM3nyZJOSkmKKiorMsWPHnI4Ul1atWmWysrJMSkqKeeqpp8yqVavM+fPnnY4VN44cOWIk3bOVl5cbY/79ldNNmzaZjIwM43K5TElJiWltbXU2dAwbaL5v3rxpFi9ebJ588kmTnJxscnNzzdq1a01HR4fTsWPS/eZZkvn+++9DY/7++2/z3nvvmYkTJ5qxY8ea1157zVy+fNm50DHsYfN98eJFs3DhQpOammpcLpeZPn26+eCDD0wgEHAsc8J/ggMAAAzZiLnHAgAAxD6KBQAAsIZiAQAArKFYAAAAaygWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALCGYgEAAKz5X0oxgBkRXdIDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f99e565b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xenc: 5 x 27\n",
    "# W: 27 x 27\n",
    "# xenc @ W: 5 x 27\n",
    "# b: 1 x 27\n",
    "\n",
    "output = xenc@W + b\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "268212f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0294, 0.0495, 0.0214, 0.0271, 0.0405, 0.0393, 0.0264, 0.0334, 0.0254,\n",
       "        0.0506, 0.0365, 0.0340, 0.0306, 0.0361, 0.0889, 0.0278, 0.0535, 0.0395,\n",
       "        0.0170, 0.0223, 0.0242, 0.0284, 0.0777, 0.0431, 0.0434, 0.0168, 0.0371],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = output.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "probs[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfa3b499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0294, 0.0495, 0.0214, 0.0271, 0.0405, 0.0393, 0.0264, 0.0334, 0.0254,\n",
       "        0.0506, 0.0365, 0.0340, 0.0306, 0.0361, 0.0889, 0.0278, 0.0535, 0.0395,\n",
       "        0.0170, 0.0223, 0.0242, 0.0284, 0.0777, 0.0431, 0.0434, 0.0168, 0.0371],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output, dim=1)[0,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efb6666e",
   "metadata": {},
   "source": [
    "# Training loop ( - 01:47:00)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3974add9",
   "metadata": {},
   "source": [
    "- get loss by taking nn-prob of actual next character\n",
    "    - should be high --> neg. --> should be low\n",
    "    - .log().mean()\n",
    "- backward pass (set gradients to None)\n",
    "- learning rate of 50 for now\n",
    "- run training loop over all xs for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2adfa4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.1338, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn evaluation\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "\n",
    "output = xenc@W + b\n",
    "probs = F.softmax(output, dim=1)\n",
    "\n",
    "# actual next characters for each x in xs is in ys\n",
    "predictions = probs[torch.arange(len(ys)), ys]\n",
    "loss = predictions.log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "903cd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build training set with all data\n",
    "bigrams = torch.zeros((len(characters), len(characters)))\n",
    "start = '.'\n",
    "end = '.'\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for name in names:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        xs.append(row_index)\n",
    "        ys.append(col_index)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcebb2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3382649421691895\n",
      "3.0802760124206543\n",
      "2.9226419925689697\n",
      "2.828274726867676\n",
      "2.764129161834717\n",
      "2.7179553508758545\n",
      "2.6836931705474854\n",
      "2.6574463844299316\n",
      "2.6367342472076416\n",
      "2.6199684143066406\n",
      "2.606107473373413\n",
      "2.5944442749023438\n",
      "2.5844836235046387\n",
      "2.5758697986602783\n",
      "2.568338394165039\n",
      "2.561690330505371\n",
      "2.5557734966278076\n",
      "2.550469398498535\n",
      "2.5456840991973877\n",
      "2.5413424968719482\n",
      "2.537384033203125\n",
      "2.5337586402893066\n",
      "2.5304250717163086\n",
      "2.5273492336273193\n",
      "2.5245025157928467\n",
      "2.5218586921691895\n",
      "2.5193982124328613\n",
      "2.517101526260376\n",
      "2.514953851699829\n",
      "2.5129404067993164\n",
      "2.51104998588562\n",
      "2.509270668029785\n",
      "2.5075936317443848\n",
      "2.5060102939605713\n",
      "2.504513740539551\n",
      "2.503096103668213\n",
      "2.5017521381378174\n",
      "2.5004758834838867\n",
      "2.499262571334839\n",
      "2.498108148574829\n",
      "2.4970076084136963\n",
      "2.495958089828491\n",
      "2.494955539703369\n",
      "2.49399733543396\n",
      "2.4930806159973145\n",
      "2.4922029972076416\n",
      "2.491361379623413\n",
      "2.490554094314575\n",
      "2.489778995513916\n",
      "2.4890341758728027\n",
      "2.4883177280426025\n",
      "2.4876291751861572\n",
      "2.4869654178619385\n",
      "2.486325979232788\n",
      "2.4857091903686523\n",
      "2.485114574432373\n",
      "2.4845399856567383\n",
      "2.483985424041748\n",
      "2.4834492206573486\n",
      "2.4829306602478027\n",
      "2.482429027557373\n",
      "2.481943368911743\n",
      "2.481472969055176\n",
      "2.4810168743133545\n",
      "2.4805748462677\n",
      "2.4801464080810547\n",
      "2.4797306060791016\n",
      "2.4793267250061035\n",
      "2.4789350032806396\n",
      "2.4785540103912354\n",
      "2.4781839847564697\n",
      "2.4778239727020264\n",
      "2.477473735809326\n",
      "2.4771335124969482\n",
      "2.476802110671997\n",
      "2.4764795303344727\n",
      "2.476165294647217\n",
      "2.4758591651916504\n",
      "2.4755611419677734\n",
      "2.4752700328826904\n",
      "2.4749863147735596\n",
      "2.474709987640381\n",
      "2.474440097808838\n",
      "2.4741768836975098\n",
      "2.473919630050659\n",
      "2.4736690521240234\n",
      "2.473423719406128\n",
      "2.47318434715271\n",
      "2.4729506969451904\n",
      "2.472722053527832\n",
      "2.4724984169006348\n",
      "2.4722797870635986\n",
      "2.4720661640167236\n",
      "2.4718570709228516\n",
      "2.4716525077819824\n",
      "2.471452236175537\n",
      "2.4712560176849365\n",
      "2.471064329147339\n",
      "2.470876693725586\n",
      "2.4706926345825195\n"
     ]
    }
   ],
   "source": [
    "# initialize nn\n",
    "n_epochs = 100\n",
    "lr = 50\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.rand(size=(27,27), requires_grad=True, generator=g)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    output = xenc@W\n",
    "    probs = F.softmax(output, dim=1)\n",
    "\n",
    "    # loss\n",
    "    predictions = probs[torch.arange(len(ys)), ys]\n",
    "    loss = -predictions.log().mean()\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    with torch.no_grad():\n",
    "        W -= lr * W.grad\n",
    "    \n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8e2958d",
   "metadata": {},
   "source": [
    "# Notes ( - end)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b156657",
   "metadata": {},
   "source": [
    "- matrix multiply with one-hot encoded vector is the same as row-lookup (does indexing work with autograd?)\n",
    "- fake-counts is the same as regularization\n",
    "    -  + (W**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83aaaced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3382649421691895\n",
      "3.080275535583496\n",
      "2.922642469406128\n",
      "2.8282742500305176\n",
      "2.7641282081604004\n",
      "2.7179553508758545\n",
      "2.683692216873169\n",
      "2.6574456691741943\n",
      "2.6367340087890625\n",
      "2.6199681758880615\n",
      "2.606107234954834\n",
      "2.5944442749023438\n",
      "2.5844836235046387\n",
      "2.5758700370788574\n",
      "2.56833815574646\n",
      "2.561690330505371\n",
      "2.5557734966278076\n",
      "2.550469398498535\n",
      "2.5456840991973877\n",
      "2.5413424968719482\n",
      "2.537384033203125\n",
      "2.5337588787078857\n",
      "2.5304250717163086\n",
      "2.5273494720458984\n",
      "2.5245025157928467\n",
      "2.5218586921691895\n",
      "2.5193982124328613\n",
      "2.517101764678955\n",
      "2.51495361328125\n",
      "2.5129404067993164\n",
      "2.511049509048462\n",
      "2.509270668029785\n",
      "2.5075936317443848\n",
      "2.5060107707977295\n",
      "2.504513740539551\n",
      "2.503096103668213\n",
      "2.5017521381378174\n",
      "2.500476121902466\n",
      "2.499262809753418\n",
      "2.49810791015625\n",
      "2.4970076084136963\n",
      "2.495957851409912\n",
      "2.494955539703369\n",
      "2.49399733543396\n",
      "2.4930806159973145\n",
      "2.4922029972076416\n",
      "2.491361379623413\n",
      "2.490554094314575\n",
      "2.489778995513916\n",
      "2.4890341758728027\n",
      "2.4883179664611816\n",
      "2.487628698348999\n",
      "2.4869654178619385\n",
      "2.486325979232788\n",
      "2.4857091903686523\n",
      "2.485114336013794\n",
      "2.4845399856567383\n",
      "2.483985662460327\n",
      "2.4834492206573486\n",
      "2.4829306602478027\n",
      "2.482428789138794\n",
      "2.481943368911743\n",
      "2.4814727306365967\n",
      "2.4810171127319336\n",
      "2.4805753231048584\n",
      "2.4801461696624756\n",
      "2.4797306060791016\n",
      "2.4793267250061035\n",
      "2.4789347648620605\n",
      "2.4785542488098145\n",
      "2.4781839847564697\n",
      "2.4778239727020264\n",
      "2.477473735809326\n",
      "2.4771335124969482\n",
      "2.476802110671997\n",
      "2.4764795303344727\n",
      "2.476165294647217\n",
      "2.4758591651916504\n",
      "2.4755609035491943\n",
      "2.4752702713012695\n",
      "2.4749863147735596\n",
      "2.474709987640381\n",
      "2.474440097808838\n",
      "2.4741768836975098\n",
      "2.473919630050659\n",
      "2.4736690521240234\n",
      "2.473423719406128\n",
      "2.47318434715271\n",
      "2.4729504585266113\n",
      "2.472722053527832\n",
      "2.4724984169006348\n",
      "2.4722797870635986\n",
      "2.4720661640167236\n",
      "2.4718570709228516\n",
      "2.4716522693634033\n",
      "2.471452236175537\n",
      "2.4712560176849365\n",
      "2.471064329147339\n",
      "2.470876693725586\n",
      "2.4706923961639404\n"
     ]
    }
   ],
   "source": [
    "# initialize nn\n",
    "n_epochs = 100\n",
    "lr = 50\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.rand(size=(27,27), requires_grad=True, generator=g)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass\n",
    "    output = W[xs,:]\n",
    "    probs = F.softmax(output, dim=1)\n",
    "\n",
    "\n",
    "    # loss\n",
    "    predictions = probs[torch.arange(len(ys)), ys]\n",
    "    loss = -predictions.log().mean()\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    with torch.no_grad():\n",
    "        W -= lr * W.grad\n",
    "    \n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72d12541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3382649421691895\n",
      "3.080183506011963\n",
      "2.922731399536133\n",
      "2.8285632133483887\n",
      "2.7646055221557617\n",
      "2.718595504760742\n",
      "2.684464693069458\n",
      "2.6583266258239746\n",
      "2.6377055644989014\n",
      "2.621018648147583\n",
      "2.607226848602295\n",
      "2.595625162124634\n",
      "2.5857207775115967\n",
      "2.577158212661743\n",
      "2.569673776626587\n",
      "2.563070297241211\n",
      "2.5571959018707275\n",
      "2.551931858062744\n",
      "2.547184705734253\n",
      "2.542879819869995\n",
      "2.5389564037323\n",
      "2.535365343093872\n",
      "2.532064437866211\n",
      "2.529020309448242\n",
      "2.5262036323547363\n",
      "2.5235893726348877\n",
      "2.5211572647094727\n",
      "2.518888235092163\n",
      "2.516766309738159\n",
      "2.5147786140441895\n",
      "2.5129122734069824\n",
      "2.5111570358276367\n",
      "2.509503126144409\n",
      "2.507941961288452\n",
      "2.506466865539551\n",
      "2.505070209503174\n",
      "2.503746271133423\n",
      "2.5024895668029785\n",
      "2.501295328140259\n",
      "2.5001585483551025\n",
      "2.4990763664245605\n",
      "2.4980435371398926\n",
      "2.497058153152466\n",
      "2.4961161613464355\n",
      "2.49521541595459\n",
      "2.4943530559539795\n",
      "2.4935264587402344\n",
      "2.49273419380188\n",
      "2.491973400115967\n",
      "2.4912424087524414\n",
      "2.4905402660369873\n",
      "2.4898645877838135\n",
      "2.4892141819000244\n",
      "2.4885873794555664\n",
      "2.487983465194702\n",
      "2.487401247024536\n",
      "2.4868388175964355\n",
      "2.4862959384918213\n",
      "2.485771417617798\n",
      "2.485264539718628\n",
      "2.484774112701416\n",
      "2.484299421310425\n",
      "2.483839750289917\n",
      "2.4833948612213135\n",
      "2.482963800430298\n",
      "2.4825456142425537\n",
      "2.482140064239502\n",
      "2.4817466735839844\n",
      "2.4813644886016846\n",
      "2.4809937477111816\n",
      "2.480633020401001\n",
      "2.48028302192688\n",
      "2.479942560195923\n",
      "2.479611396789551\n",
      "2.4792895317077637\n",
      "2.478976011276245\n",
      "2.478671073913574\n",
      "2.4783737659454346\n",
      "2.4780843257904053\n",
      "2.477802276611328\n",
      "2.477527618408203\n",
      "2.477259635925293\n",
      "2.4769983291625977\n",
      "2.476743459701538\n",
      "2.4764950275421143\n",
      "2.476252317428589\n",
      "2.476015329360962\n",
      "2.4757840633392334\n",
      "2.4755585193634033\n",
      "2.475337505340576\n",
      "2.4751219749450684\n",
      "2.4749114513397217\n",
      "2.474705457687378\n",
      "2.474503993988037\n",
      "2.47430682182312\n",
      "2.474114179611206\n",
      "2.473926067352295\n",
      "2.473741292953491\n",
      "2.4735610485076904\n",
      "2.473384380340576\n"
     ]
    }
   ],
   "source": [
    "# initialize nn\n",
    "n_epochs = 100\n",
    "lr = 50\n",
    "l2 = .01\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.rand(size=(27,27), requires_grad=True, generator=g)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass\n",
    "    output = W[xs,:]\n",
    "    probs = F.softmax(output, dim=1)\n",
    "\n",
    "\n",
    "    # loss\n",
    "    predictions = probs[torch.arange(len(ys)), ys]\n",
    "    loss = -predictions.log().mean() + l2 * (W**2).mean()\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    with torch.no_grad():\n",
    "        W -= lr * W.grad\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        # loss without regularization term\n",
    "        loss = -predictions.log().mean()\n",
    "        print(loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f718faa5",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08a633bd",
   "metadata": {},
   "source": [
    "## #1 Trigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2bfc167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build training set\n",
    "start = ['.']\n",
    "end = ['.']\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for name in names:\n",
    "    name = 2*start + list(name) + end\n",
    "    for ch1,ch2,ch3 in zip(name, name[1:], name[2:]):\n",
    "        #print(f'({ch1}{ch2}: {ch3}')\n",
    "        xs.append([stoi[ch1], 27+stoi[ch2]])\n",
    "        ys.append(stoi[ch3])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7c03bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1, 28],\n",
       "         [ 1, 40],\n",
       "         [13, 43],\n",
       "         [16, 43],\n",
       "         [16, 48]]),\n",
       " tensor([13, 16, 16, 21,  1]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:5], ys[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "822947f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.3666110038757324\n",
      "50 2.4660329818725586\n",
      "100 2.416826009750366\n",
      "150 2.395254135131836\n",
      "200 2.382878065109253\n",
      "250 2.3747732639312744\n",
      "300 2.369027853012085\n",
      "350 2.3684580326080322\n",
      "400 2.367990493774414\n",
      "450 2.3675355911254883\n",
      "500 2.3670926094055176\n",
      "550 2.366661787033081\n",
      "600 2.3662424087524414\n",
      "650 2.3661937713623047\n",
      "700 2.366152286529541\n",
      "750 2.3661112785339355\n",
      "800 2.366070032119751\n",
      "850 2.3660292625427246\n",
      "900 2.3659884929656982\n",
      "950 2.365983724594116\n"
     ]
    }
   ],
   "source": [
    "# initialize nn\n",
    "n_epochs = 1000\n",
    "lr = 100\n",
    "l2 = .0\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.rand(size=(54,27), requires_grad=True, generator=g)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass\n",
    "    output = W[xs].sum(dim=1)\n",
    "    probs = F.softmax(output, dim=1)\n",
    "\n",
    "    # loss\n",
    "    predictions = probs[torch.arange(len(ys)), ys]\n",
    "    loss = -predictions.log().mean() + l2 * (W**2).mean()\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    with torch.no_grad():\n",
    "        W -= lr * W.grad\n",
    "    \n",
    "\n",
    "    if epoch%50==0:\n",
    "        print(epoch, loss.item())\n",
    "\n",
    "    if epoch%300==0:\n",
    "        lr /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4f4ac95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..aadyd.\n",
      "..az.\n",
      "..asmdzetpsiquri.\n",
      "..uaiuxmers.\n",
      "..eln.\n",
      "..ae.\n",
      "..aaaen.\n",
      "..azqebarcoe.\n",
      "..oe.\n",
      "..aelesiely.\n"
     ]
    }
   ],
   "source": [
    "# sampling\n",
    "\n",
    "for _ in range(10):\n",
    "    name = '..'\n",
    "    while True:\n",
    "        ch1 = stoi[name[-2]]\n",
    "        ch2 = stoi[name[-1]]\n",
    "\n",
    "        logits = W[[ch1, ch2]].sum(dim=0)\n",
    "        probs = F.softmax(logits, dim=0)\n",
    "\n",
    "        next = torch.multinomial(probs, 1, replacement=True)\n",
    "        next_char = itos[next.item()]\n",
    "        name = name + next_char\n",
    "\n",
    "        if next_char=='.':\n",
    "            break\n",
    "\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5273e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e98ef4f9346bee673f51c6ffc649e77c3dd738815ba08794b113970bacedb832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
