{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19f72cf-8e59-4264-96b0-946053cef7dc",
   "metadata": {},
   "source": [
    "# The spelled-out intro to language modeling: building makemore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c69cb-854d-4c19-b237-b5ba194a4591",
   "metadata": {},
   "source": [
    "Following: https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a512cfd5-1a33-4f3d-92fe-433b57d50f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d0d6571-963f-4cd1-8bc4-566c2d07a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d69bd-2701-4f63-a922-8f27d9d98dca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Exploring bigrams (0:00 - 0:15:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71232cb1-ecf2-46b6-b36e-5b4eaa751075",
   "metadata": {},
   "source": [
    "Tasks done in the video:\n",
    "- Load the dataset\n",
    "- Explore\n",
    "    - min/max length of names\n",
    "    - number of names\n",
    "- count all the bigrams into a dictionary\n",
    "    - dedicated \\<S\\> and \\<E\\> tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813b672a-fd7b-43fe-b5c6-864fc318b781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = (data/'names.txt').open().read().splitlines()\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec49eac-8297-4e3c-9797-1b07eeb3adce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02d0830-5e4f-4e57-959d-a70e0cdaa225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(name) for name in names), max(len(name) for name in names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce29c4b-f415-4d3e-917d-ad5492b732f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = defaultdict(int)\n",
    "start = '<S>'\n",
    "end = '<E>'\n",
    "\n",
    "for name in names:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        bigrams[(ch1,ch2)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e00e97-cf84-4882-8a64-6aef06f796ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '<E>'), 6763),\n",
       " (('a', '<E>'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('<S>', 'a'), 4410),\n",
       " (('e', '<E>'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('<S>', 'k'), 2963)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((bigram_tuples for bigram_tuples in bigrams.items()), key=lambda b: b[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a061496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58c250c6-d481-4889-b5c6-276218446e3b",
   "metadata": {},
   "source": [
    "# Bigrams into torch.Tensor ( - 00:36:00, skipping efficiency until 00:50:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb66ea-8792-43e7-b979-d973267e1fe1",
   "metadata": {},
   "source": [
    "- Goal: n*n matrix that holds the bigram count in each cell\n",
    "- No more dedicated start/stopping tokens, instead use . for both\n",
    "- sample from the model\n",
    "    - start with the starting dot\n",
    "    - choose random next character according to probabilities in that row (torch.multinomial)\n",
    "    - repeat until ending-dot is reached\n",
    "    - Use torch.Generator for comparability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1b3ce-ef5d-4ae7-a5f5-fb1dc9948c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bigrams to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd60e0bb-ea36-4d0f-a5e9-f58f523ba331",
   "metadata": {},
   "source": [
    "Extracting all used characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554df160-1fb3-4b68-9ae9-3d616f74374e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = set('.')\n",
    "characters = characters.union(set(''.join(names)))\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae5f08b-d19e-462e-9c32-8cef882d03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "563dd508-65ad-4544-89c2-4f8136cc2419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': 0,\n",
       " 'h': 1,\n",
       " 'o': 2,\n",
       " 'x': 3,\n",
       " '.': 4,\n",
       " 'e': 5,\n",
       " 'p': 6,\n",
       " 'c': 7,\n",
       " 'q': 8,\n",
       " 'w': 9,\n",
       " 'm': 10,\n",
       " 'u': 11,\n",
       " 'j': 12,\n",
       " 't': 13,\n",
       " 'y': 14,\n",
       " 'f': 15,\n",
       " 'a': 16,\n",
       " 'r': 17,\n",
       " 'v': 18,\n",
       " 'k': 19,\n",
       " 's': 20,\n",
       " 'b': 21,\n",
       " 'g': 22,\n",
       " 'd': 23,\n",
       " 'i': 24,\n",
       " 'n': 25,\n",
       " 'l': 26}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {char: i for i,char in enumerate(characters)}\n",
    "itos = {i: char for char,i in stoi.items()}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b31e1b-f04b-4c0d-96cd-1eef0ea5a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = torch.zeros((len(characters), len(characters)))\n",
    "start = '.'\n",
    "end = '.'\n",
    "\n",
    "for name in names:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        bigrams[row_index, col_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219d08e-c726-47c8-a88a-e6090fbb1704",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911228de-7e7d-4bb6-b260-a2df6548e9f1",
   "metadata": {},
   "source": [
    "Counts for characters following the start character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f3a711c-c41d-4dfb-a518-05d4fb92edb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 929.,  874.,  394.,  134.,    0., 1531.,  515., 1542.,   92.,  307.,\n",
       "        2538.,   78., 2422., 1308.,  535.,  417., 4410., 1639.,  376., 2963.,\n",
       "        2055., 1306.,  669., 1690.,  591., 1146., 1572.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[stoi[start],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a141f0-695a-4cb6-87a6-003b36f72927",
   "metadata": {},
   "source": [
    "Drawing a sample with counts as weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77339bbd-9233-493f-98ca-3d9db16efaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_idx = torch.multinomial(bigrams[stoi[start],:], 1, replacement=True).item()\n",
    "next_char = itos[next_idx]\n",
    "next_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7e4cb-fc64-4ee0-861d-ee7628835f50",
   "metadata": {},
   "source": [
    "Repeat until the stopping token is drawn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a236d426-4aff-4062-8882-da71aeb9ccc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".kkah.\n",
      ".nn.\n",
      ".kaswnanilami.\n",
      ".anevi.\n",
      ".tr.\n",
      ".joharalynn.\n",
      ".bry.\n",
      ".somatyey.\n",
      ".myene.\n",
      ".torgrranyabemulianzy.\n",
      ".ciz.\n",
      ".warli.\n",
      ".yausoddena.\n",
      ".madeiz.\n",
      ".m.\n",
      ".jo.\n",
      ".aiakay.\n",
      ".higin.\n",
      ".rayanisi.\n",
      ".jie.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    name = start\n",
    "    while True:\n",
    "        next_idx = torch.multinomial(bigrams[stoi[name[-1]],:], 1, replacement=True, generator=g).item()\n",
    "        next_char = itos[next_idx]\n",
    "        name += next_char\n",
    "\n",
    "        if next_char == end:\n",
    "            break\n",
    "\n",
    "\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a77b4-f1ca-4bf4-95e1-88d9b6b2c65b",
   "metadata": {},
   "source": [
    "Sanity-Check: Drawing with uniform probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c09bc386-e3b6-4abe-8ab4-e6bc7d110798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".rgkhhniorvrtnrdblywghybufs.\n",
      ".mg.\n",
      ".q.\n",
      ".zryfntsl.\n",
      ".bruhs.\n",
      ".esuapm.\n",
      ".cwcgjempuvkrjdywvcqqldjbzw.\n",
      ".xizxeutlbxmymfefgmgvccrvmvzxpoqhoukjafuxzisidoatuybbki.\n",
      ".clpeiqdraj.\n",
      ".a.\n",
      ".ydlgunikrmpfvrrapiksdupfbpqgdpqtkbnnfsgxggrapxon.\n",
      ".mxfbquhmuqryyarttjjhfv.\n",
      ".rnzckladzljcwmwyhycllbbjkngrvbpbhdhgk.\n",
      ".oydgjtvnagcvkpcakqcytdhprtkm.\n",
      ".goqycgfwwciqud.\n",
      ".jsv.\n",
      ".udyhclnuyrgzjpks.\n",
      ".rwcgyx.\n",
      ".fw.\n",
      ".eskbuc.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "weights = torch.ones(len(characters))\n",
    "\n",
    "for i in range(20):\n",
    "    name = start\n",
    "    while True:\n",
    "        next_idx = torch.multinomial(weights, 1, replacement=True, generator=g).item()\n",
    "        next_char = itos[next_idx]\n",
    "        name += next_char\n",
    "\n",
    "        if next_char == end:\n",
    "            break\n",
    "\n",
    "\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c9bed-8748-482c-b958-9aef3999a7c8",
   "metadata": {},
   "source": [
    "# Loss function ( - 01:03:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8711cb9-5fd5-429d-9a59-fd2778a56b44",
   "metadata": {},
   "source": [
    "- negative Likelihood is used to measure loss (product of probabilities)\n",
    "- use logs for numerical purposes (turns into the sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae0f8860-3d79-4b58-b90b-5c32b4ed7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = bigrams / bigrams.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b68377e6-902b-4da7-a1ab-e1bd07a116b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(., e): -3.0408453941345215\n",
      "(e, m): -3.2793259620666504\n",
      "(m, m): -3.6772043704986572\n",
      "(m, a): -0.9417552351951599\n",
      "(a, .): -1.6298604011535645\n",
      "Neg. Log-Likelihood: 12.568990707397461\n",
      "Mean Neg. Log-Likelihood: 2.513798236846924\n",
      "\n",
      "(., o): -4.3981709480285645\n",
      "(o, l): -2.550807476043701\n",
      "(l, i): -1.7277942895889282\n",
      "(i, v): -4.186665058135986\n",
      "(v, i): -1.0382850170135498\n",
      "(i, a): -1.9795759916305542\n",
      "(a, .): -1.6298604011535645\n",
      "Neg. Log-Likelihood: 17.511159896850586\n",
      "Mean Neg. Log-Likelihood: 2.501594305038452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in names[:2]:\n",
    "    name = [start] + list(name) + [end]\n",
    "    log_likelihood = 0\n",
    "    n = 0\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        prob = P[row_index, col_index]\n",
    "        log = torch.log(prob)\n",
    "        log_likelihood += log\n",
    "        n += 1\n",
    "        \n",
    "        print(f'({ch1}, {ch2}): {log}')\n",
    "    print(f'Neg. Log-Likelihood: {-log_likelihood}')\n",
    "    print(f'Mean Neg. Log-Likelihood: {-log_likelihood / n}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcfb9010-b329-4821-b8cf-67f931aefbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(., a): -1.9828919172286987\n",
      "(a, n): -1.8295611143112183\n",
      "(n, d): -3.259352207183838\n",
      "(d, r): -2.562042474746704\n",
      "(r, e): -2.012739896774292\n",
      "(e, j): -5.917083740234375\n",
      "(j, .): -3.7097861766815186\n",
      "Neg. Log-Likelihood: 21.273456573486328\n",
      "Mean Neg. Log-Likelihood: 3.03906512260437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in ['andrej']:\n",
    "    name = [start] + list(name) + [end]\n",
    "    log_likelihood = 0\n",
    "    n = 0\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        prob = P[row_index, col_index]\n",
    "        log = torch.log(prob)\n",
    "        log_likelihood += log\n",
    "        n += 1\n",
    "        \n",
    "        print(f'({ch1}, {ch2}): {log}')\n",
    "    print(f'Neg. Log-Likelihood: {-log_likelihood}')\n",
    "    print(f'Mean Neg. Log-Likelihood: {-log_likelihood / n}')\n",
    "    print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c9db0de-d554-4371-802b-73dde5119e3f",
   "metadata": {},
   "source": [
    "# Neural Network Approach ( - 01:25:00)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0e1b4c5-b87a-4741-9058-d38e4b577c84",
   "metadata": {},
   "source": [
    "- create training set\n",
    "    - x tensor with first letter\n",
    "    - y tensor with second letter\n",
    "- use one-hot encoding to feed indices into nn\n",
    "- \"nn\" is for now just a weight matrix and bias vector with grads\n",
    "- output should be 27 dimensional\n",
    "    - turn into \"probabilities\" by softmax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a314c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = torch.zeros((len(characters), len(characters)))\n",
    "start = '.'\n",
    "end = '.'\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for name in names[:1]:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        xs.append(row_index)\n",
    "        ys.append(col_index)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66debec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "W = torch.rand(size=(27,27), requires_grad=True, generator=g)\n",
    "b = torch.rand(size=(1,27), requires_grad=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "463af69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8610746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fb05de6190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f99e565b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xenc: 5 x 27\n",
    "# W: 27 x 27\n",
    "# xenc @ W: 5 x 27\n",
    "# b: 1 x 27\n",
    "\n",
    "output = xenc@W + b\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "268212f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0283, 0.0292, 0.0243, 0.0188, 0.0369, 0.0626, 0.0169, 0.0544, 0.0419,\n",
       "        0.0219, 0.0340, 0.0302, 0.0352, 0.0257, 0.0523, 0.0300, 0.0549, 0.0249,\n",
       "        0.0319, 0.0340, 0.0427, 0.0363, 0.0502, 0.0719, 0.0556, 0.0293, 0.0259],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = output.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "probs[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfa3b499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0283, 0.0292, 0.0243, 0.0188, 0.0369, 0.0626, 0.0169, 0.0544, 0.0419,\n",
       "        0.0219, 0.0340, 0.0302, 0.0352, 0.0257, 0.0523, 0.0300, 0.0549, 0.0249,\n",
       "        0.0319, 0.0340, 0.0427, 0.0363, 0.0502, 0.0719, 0.0556, 0.0293, 0.0259],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output, dim=1)[0,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efb6666e",
   "metadata": {},
   "source": [
    "# Training loop ( - 01:47:00)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3974add9",
   "metadata": {},
   "source": [
    "- get loss by fetching probs from normalized count matrix\n",
    "    - .log().mean()\n",
    "- backward pass (set gradients to None)\n",
    "- learning rate of 50 for now\n",
    "- run training loop over all xs for now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e98ef4f9346bee673f51c6ffc649e77c3dd738815ba08794b113970bacedb832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
