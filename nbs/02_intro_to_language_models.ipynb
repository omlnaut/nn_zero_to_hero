{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19f72cf-8e59-4264-96b0-946053cef7dc",
   "metadata": {},
   "source": [
    "# The spelled-out intro to language modeling: building makemore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c69cb-854d-4c19-b237-b5ba194a4591",
   "metadata": {},
   "source": [
    "Following: https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a512cfd5-1a33-4f3d-92fe-433b57d50f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0d6571-963f-4cd1-8bc4-566c2d07a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d69bd-2701-4f63-a922-8f27d9d98dca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Exploring bigrams (0:00 - 0:15:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71232cb1-ecf2-46b6-b36e-5b4eaa751075",
   "metadata": {},
   "source": [
    "Tasks done in the video:\n",
    "- Load the dataset\n",
    "- Explore\n",
    "    - min/max length of names\n",
    "    - number of names\n",
    "- count all the bigrams into a dictionary\n",
    "    - dedicated \\<S\\> and \\<E\\> tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813b672a-fd7b-43fe-b5c6-864fc318b781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = (data/'names.txt').open().read().splitlines()\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec49eac-8297-4e3c-9797-1b07eeb3adce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e02d0830-5e4f-4e57-959d-a70e0cdaa225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(name) for name in names), max(len(name) for name in names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce29c4b-f415-4d3e-917d-ad5492b732f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = defaultdict(int)\n",
    "start = '<S>'\n",
    "end = '<E>'\n",
    "\n",
    "for name in names:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        bigrams[(ch1,ch2)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e00e97-cf84-4882-8a64-6aef06f796ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '<E>'), 6763),\n",
       " (('a', '<E>'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('<S>', 'a'), 4410),\n",
       " (('e', '<E>'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('<S>', 'k'), 2963)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((bigram_tuples for bigram_tuples in bigrams.items()), key=lambda b: b[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a061496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58c250c6-d481-4889-b5c6-276218446e3b",
   "metadata": {},
   "source": [
    "# Bigrams into torch.Tensor ( - 00:36:00, skipping efficiency until 00:50:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb66ea-8792-43e7-b979-d973267e1fe1",
   "metadata": {},
   "source": [
    "- Goal: n*n matrix that holds the bigram count in each cell\n",
    "- No more dedicated start/stopping tokens, instead use . for both\n",
    "- sample from the model\n",
    "    - start with the starting dot\n",
    "    - choose random next character according to probabilities in that row (torch.multinomial)\n",
    "    - repeat until ending-dot is reached\n",
    "    - Use torch.Generator for comparability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1b3ce-ef5d-4ae7-a5f5-fb1dc9948c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bigrams to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd60e0bb-ea36-4d0f-a5e9-f58f523ba331",
   "metadata": {},
   "source": [
    "Extracting all used characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554df160-1fb3-4b68-9ae9-3d616f74374e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = set('.')\n",
    "characters = characters.union(set(''.join(names)))\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae5f08b-d19e-462e-9c32-8cef882d03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "563dd508-65ad-4544-89c2-4f8136cc2419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 0,\n",
       " 'm': 1,\n",
       " 'y': 2,\n",
       " 'f': 3,\n",
       " 'w': 4,\n",
       " 'q': 5,\n",
       " 's': 6,\n",
       " 'v': 7,\n",
       " 't': 8,\n",
       " 'e': 9,\n",
       " 'p': 10,\n",
       " 'd': 11,\n",
       " 'b': 12,\n",
       " 'u': 13,\n",
       " '.': 14,\n",
       " 'z': 15,\n",
       " 'c': 16,\n",
       " 'k': 17,\n",
       " 'j': 18,\n",
       " 'r': 19,\n",
       " 'i': 20,\n",
       " 'o': 21,\n",
       " 'l': 22,\n",
       " 'x': 23,\n",
       " 'h': 24,\n",
       " 'g': 25,\n",
       " 'a': 26}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {char: i for i,char in enumerate(characters)}\n",
    "itos = {i: char for char,i in stoi.items()}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b31e1b-f04b-4c0d-96cd-1eef0ea5a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = torch.zeros((len(characters), len(characters)))\n",
    "start = '.'\n",
    "end = '.'\n",
    "\n",
    "for name in names:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        bigrams[row_index, col_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219d08e-c726-47c8-a88a-e6090fbb1704",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911228de-7e7d-4bb6-b260-a2df6548e9f1",
   "metadata": {},
   "source": [
    "Counts for characters following the start character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f3a711c-c41d-4dfb-a518-05d4fb92edb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1146., 2538.,  535.,  417.,  307.,   92., 2055.,  376., 1308., 1531.,\n",
       "         515., 1690., 1306.,   78.,    0.,  929., 1542., 2963., 2422., 1639.,\n",
       "         591.,  394., 1572.,  134.,  874.,  669., 4410.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[stoi[start],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a141f0-695a-4cb6-87a6-003b36f72927",
   "metadata": {},
   "source": [
    "Drawing a sample with counts as weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77339bbd-9233-493f-98ca-3d9db16efaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_idx = torch.multinomial(bigrams[stoi[start],:], 1, replacement=True).item()\n",
    "next_char = itos[next_idx]\n",
    "next_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7e4cb-fc64-4ee0-861d-ee7628835f50",
   "metadata": {},
   "source": [
    "Repeat until the stopping token is drawn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a236d426-4aff-4062-8882-da71aeb9ccc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".jarynahto.\n",
      ".jahoora.\n",
      ".dan.\n",
      ".l.\n",
      ".kan.\n",
      ".heten.\n",
      ".kla.\n",
      ".iano.\n",
      ".beiysh.\n",
      ".j.\n",
      ".besush.\n",
      ".s.\n",
      ".trio.\n",
      ".za.\n",
      ".don.\n",
      ".pal.\n",
      ".lmiynanymi.\n",
      ".ain.\n",
      ".krisigrakevir.\n",
      ".rnsen.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    name = start\n",
    "    while True:\n",
    "        next_idx = torch.multinomial(bigrams[stoi[name[-1]],:], 1, replacement=True, generator=g).item()\n",
    "        next_char = itos[next_idx]\n",
    "        name += next_char\n",
    "\n",
    "        if next_char == end:\n",
    "            break\n",
    "\n",
    "\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a77b4-f1ca-4bf4-95e1-88d9b6b2c65b",
   "metadata": {},
   "source": [
    "Sanity-Check: Drawing with uniform probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09bc386-e3b6-4abe-8ab4-e6bc7d110798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".klrmmghykjkugkxoa.\n",
      ".elm.\n",
      ".odziwplwtwnk.\n",
      ".zguiawokdmiwqidcspwvevlbqpsdjrkbx.\n",
      ".ejvttaxbonewfhnfqduaofp.\n",
      ".pzqzlpljvvkjpjnfsytmydrbczdfnhihxycud.\n",
      ".oorhwvasqhtxkcbwcw.\n",
      ".xaldghrkpszjkkcshrixdszostlxsturoggzilfllkcsfygwpfzotdmpdtk.\n",
      "..\n",
      ".ckuubbmzjwkgnvracxnabvepe.\n",
      ".m.\n",
      ".vaaoobrglkjosomxmlrwy.\n",
      ".xlbujgclvjrsvcrtv.\n",
      ".uxmskurpwlyt.\n",
      ".vlzeevhtdxwbijwdx.\n",
      ".mvagd.\n",
      ".klnbsriwkevl.\n",
      ".fwzewqirodvwcnfscprhqkpfrupxvoaqrnxzsbsphsbgbvyqvcpwczlwixnwbagrkijythtfw.\n",
      ".qeoounhigrbsyumyzmm.\n",
      ".gpczpoopsbfrmofkfvipubakiymerlhjivocdccevhowqpwarjzkqevzlohulinpbhszbdzafenidtweldwesmhfqlbcdidxxlohbguixgbvcamoxwlhslyzzsbwwctupqzupvpfkqkxinnxbhfbfpyunkoogepi.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "weights = torch.ones(len(characters))\n",
    "\n",
    "for i in range(20):\n",
    "    name = start\n",
    "    while True:\n",
    "        next_idx = torch.multinomial(weights, 1, replacement=True, generator=g).item()\n",
    "        next_char = itos[next_idx]\n",
    "        name += next_char\n",
    "\n",
    "        if next_char == end:\n",
    "            break\n",
    "\n",
    "\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c9bed-8748-482c-b958-9aef3999a7c8",
   "metadata": {},
   "source": [
    "# Loss function ( - 01:03:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8711cb9-5fd5-429d-9a59-fd2778a56b44",
   "metadata": {},
   "source": [
    "- negative Likelihood is used to measure loss (product of probabilities)\n",
    "- use logs for numerical purposes (turns into the sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae0f8860-3d79-4b58-b90b-5c32b4ed7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = bigrams / bigrams.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b68377e6-902b-4da7-a1ab-e1bd07a116b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(., e): -3.0408453941345215\n",
      "(e, m): -3.2793259620666504\n",
      "(m, m): -3.6772043704986572\n",
      "(m, a): -0.9417552351951599\n",
      "(a, .): -1.6298604011535645\n",
      "Neg. Log-Likelihood: 12.568990707397461\n",
      "Mean Neg. Log-Likelihood: 2.513798236846924\n",
      "\n",
      "(., o): -4.3981709480285645\n",
      "(o, l): -2.550807476043701\n",
      "(l, i): -1.7277942895889282\n",
      "(i, v): -4.186665058135986\n",
      "(v, i): -1.0382850170135498\n",
      "(i, a): -1.9795759916305542\n",
      "(a, .): -1.6298604011535645\n",
      "Neg. Log-Likelihood: 17.511159896850586\n",
      "Mean Neg. Log-Likelihood: 2.501594305038452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in names[:2]:\n",
    "    name = [start] + list(name) + [end]\n",
    "    log_likelihood = 0\n",
    "    n = 0\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        prob = P[row_index, col_index]\n",
    "        log = torch.log(prob)\n",
    "        log_likelihood += log\n",
    "        n += 1\n",
    "        \n",
    "        print(f'({ch1}, {ch2}): {log}')\n",
    "    print(f'Neg. Log-Likelihood: {-log_likelihood}')\n",
    "    print(f'Mean Neg. Log-Likelihood: {-log_likelihood / n}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcfb9010-b329-4821-b8cf-67f931aefbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(., a): -1.9828919172286987\n",
      "(a, n): -1.8295611143112183\n",
      "(n, d): -3.259352207183838\n",
      "(d, r): -2.562042474746704\n",
      "(r, e): -2.012739896774292\n",
      "(e, j): -5.917083740234375\n",
      "(j, .): -3.7097861766815186\n",
      "Neg. Log-Likelihood: 21.273456573486328\n",
      "Mean Neg. Log-Likelihood: 3.03906512260437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in ['andrej']:\n",
    "    name = [start] + list(name) + [end]\n",
    "    log_likelihood = 0\n",
    "    n = 0\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        prob = P[row_index, col_index]\n",
    "        log = torch.log(prob)\n",
    "        log_likelihood += log\n",
    "        n += 1\n",
    "        \n",
    "        print(f'({ch1}, {ch2}): {log}')\n",
    "    print(f'Neg. Log-Likelihood: {-log_likelihood}')\n",
    "    print(f'Mean Neg. Log-Likelihood: {-log_likelihood / n}')\n",
    "    print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c9db0de-d554-4371-802b-73dde5119e3f",
   "metadata": {},
   "source": [
    "# Neural Network Approach ( - 01:25:00)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0e1b4c5-b87a-4741-9058-d38e4b577c84",
   "metadata": {},
   "source": [
    "- create training set\n",
    "    - x tensor with first letter\n",
    "    - y tensor with second letter\n",
    "- use one-hot encoding to feed indices into nn\n",
    "- \"nn\" is for now just a weight matrix and bias vector with grads\n",
    "- output should be 27 dimensional\n",
    "    - turn into \"probabilities\" by softmax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a314c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = torch.zeros((len(characters), len(characters)))\n",
    "start = '.'\n",
    "end = '.'\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for name in names[:1]:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        xs.append(row_index)\n",
    "        ys.append(col_index)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66debec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "W = torch.rand(size=(27,27), requires_grad=True, generator=g)\n",
    "b = torch.rand(size=(1,27), requires_grad=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "463af69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8610746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x249e3ed64c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f99e565b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xenc: 5 x 27\n",
    "# W: 27 x 27\n",
    "# xenc @ W: 5 x 27\n",
    "# b: 1 x 27\n",
    "\n",
    "output = xenc@W + b\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "268212f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0232, 0.0394, 0.0224, 0.0224, 0.0488, 0.0647, 0.0207, 0.0323, 0.0399,\n",
       "        0.0263, 0.0227, 0.0293, 0.0259, 0.0311, 0.0560, 0.0365, 0.0460, 0.0530,\n",
       "        0.0265, 0.0190, 0.0440, 0.0269, 0.0553, 0.0556, 0.0444, 0.0309, 0.0569],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = output.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "probs[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfa3b499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0232, 0.0394, 0.0224, 0.0224, 0.0488, 0.0647, 0.0207, 0.0323, 0.0399,\n",
       "        0.0263, 0.0227, 0.0293, 0.0259, 0.0311, 0.0560, 0.0365, 0.0460, 0.0530,\n",
       "        0.0265, 0.0190, 0.0440, 0.0269, 0.0553, 0.0556, 0.0444, 0.0309, 0.0569],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output, dim=1)[0,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efb6666e",
   "metadata": {},
   "source": [
    "# Training loop ( - 01:47:00)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3974add9",
   "metadata": {},
   "source": [
    "- get loss by taking nn-prob of actual next character\n",
    "    - should be high --> neg. --> should be low\n",
    "    - .log().mean()\n",
    "- backward pass (set gradients to None)\n",
    "- learning rate of 50 for now\n",
    "- run training loop over all xs for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2adfa4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.2191, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn evaluation\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "\n",
    "output = xenc@W + b\n",
    "probs = F.softmax(output, dim=1)\n",
    "\n",
    "# actual next characters for each x in xs is in ys\n",
    "predictions = probs[torch.arange(len(ys)), ys]\n",
    "loss = predictions.log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "903cd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build training set with all data\n",
    "bigrams = torch.zeros((len(characters), len(characters)))\n",
    "start = '.'\n",
    "end = '.'\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for name in names:\n",
    "    name = [start] + list(name) + [end]\n",
    "    for ch1,ch2 in zip(name, name[1:]):\n",
    "        row_index = stoi[ch1]\n",
    "        col_index = stoi[ch2]\n",
    "        xs.append(row_index)\n",
    "        ys.append(col_index)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcebb2d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     23\u001b[0m \u001b[39m# update\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m W \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m50\u001b[39m \u001b[39m*\u001b[39m W\u001b[39m.\u001b[39mgrad\n\u001b[0;32m     25\u001b[0m b \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m50\u001b[39m \u001b[39m*\u001b[39m b\u001b[39m.\u001b[39mgrad\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(loss\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "# initialize nn\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "W = torch.rand(size=(27,27), requires_grad=True, generator=g)\n",
    "b = torch.rand(size=(1,27), requires_grad=True, generator=g)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    output = xenc@W + b\n",
    "    probs = F.softmax(output, dim=1)\n",
    "\n",
    "    # loss\n",
    "    predictions = probs[torch.arange(len(ys)), ys]\n",
    "    loss = predictions.log().mean()\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    b.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    with torch.no_grad():\n",
    "        W -= 50 * W.grad\n",
    "        b -= 50 * b.grad\n",
    "    \n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3c322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e98ef4f9346bee673f51c6ffc649e77c3dd738815ba08794b113970bacedb832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
