{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/shakespeare.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = sorted(list(set(text)))\n",
    "''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch: i for i, ch in enumerate(tokens) }\n",
    "itos = { i: ch for i, ch in enumerate(tokens) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    return torch.tensor([stoi[ch] for ch in text], dtype=torch.long)\n",
    "\n",
    "def decode(tensor):\n",
    "    return ''.join([itos[i.item()] for i in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58, 43, 57, 58, 47])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('testi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testi'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode('testi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = encode(text)\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citi'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([892315]) torch.Size([223079])\n"
     ]
    }
   ],
   "source": [
    "split = int(0.8 * len(data))\n",
    "train = data[:split]\n",
    "val = data[split:]\n",
    "\n",
    "print(train.shape, val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a single chunk of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([64, 43, 52, 10,  0, 14, 43, 44])\n",
      "tensor([43, 52, 10,  0, 14, 43, 44, 53])\n"
     ]
    }
   ],
   "source": [
    "offset = 10 # arbitrary offset for demonstration\n",
    "\n",
    "x = train[offset:offset+block_size]\n",
    "y = train[offset+1:offset+block_size+1]\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate random offsets into the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([165150,  69139, 497238, 653945])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets = torch.randint(0, split-block_size, (batch_size,))\n",
    "offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then generate a block-size x and a shifted-by-1 block-size y for each offset, stacking those tensor into a single x and y tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[44,  8,  0,  0, 24, 13, 16, 37],\n",
      "        [ 1, 58, 46, 43, 51,  2,  0,  0],\n",
      "        [50,  0, 14, 43,  1, 57, 46, 56],\n",
      "        [ 1, 41, 53, 52, 57, 41, 47, 43]])\n",
      "tensor([[ 8,  0,  0, 24, 13, 16, 37,  1],\n",
      "        [58, 46, 43, 51,  2,  0,  0, 15],\n",
      "        [ 0, 14, 43,  1, 57, 46, 56, 47],\n",
      "        [41, 53, 52, 57, 41, 47, 43, 52]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack([data[offset : offset+block_size] for offset in offsets]))\n",
    "print(torch.stack([data[offset+1 : offset+block_size+1] for offset in offsets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, block_size=block_size, batch_size=batch_size):\n",
    "    offsets = torch.randint(0, split-block_size, (batch_size,))\n",
    "\n",
    "    xb = torch.stack([data[offset : offset+block_size] for offset in offsets])\n",
    "    yb = torch.stack([data[offset+1 : offset+block_size+1] for offset in offsets])\n",
    "\n",
    "    return xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[13, 10,  0, 21,  1, 39, 51,  1],\n",
       "         [53, 60, 43,  6,  1, 58, 46, 47],\n",
       "         [57, 11,  1, 44, 53, 56,  1, 47],\n",
       "         [47, 51,  6,  1, 21,  1, 44, 43]]),\n",
       " tensor([[10,  0, 21,  1, 39, 51,  1, 39],\n",
       "         [60, 43,  6,  1, 58, 46, 47, 57],\n",
       "         [11,  1, 44, 53, 56,  1, 47, 44],\n",
       "         [51,  6,  1, 21,  1, 44, 43, 39]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if targets is None:\n",
    "            return x, None\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(x.view(-1, self.vocab_size), targets.view(-1))\n",
    "\n",
    "        return x, loss\n",
    "\n",
    "    def generate_text(self, x, steps=500):\n",
    "        for _ in range(steps):\n",
    "            logits, _ = self(x)\n",
    "            last_logits = logits[:,-1,:]\n",
    "            probs = torch.functional.F.softmax(last_logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            x = torch.cat([x, next_token], dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, x, steps=100):\n",
    "        for _ in range(steps):\n",
    "            x, _ = self(x)\n",
    "            x = x[-1].argmax()\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokens)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = get_batch(train)\n",
    "xb.shape # (batch_size, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 65])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, loss = model(xb, yb)\n",
    "logits.shape # (batch_size, block_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6028, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 22,  8, 45, 28,  5, 31, 30, 36, 57, 11, 61,  2, 27,  5, 29, 12, 32,\n",
       "          9, 16, 15, 29, 58,  6,  4, 64, 36, 46, 49, 16, 30, 36, 18,  9, 35, 44,\n",
       "         27, 23,  0,  8,  5, 48, 43, 54,  0, 20,  8, 51, 15, 39, 22,  4, 53,  4,\n",
       "         62, 47, 10, 15, 50, 33, 31, 48,  9, 34, 62, 15, 63, 64, 62, 15, 49, 58,\n",
       "         30, 47, 50,  9, 39, 53, 16, 57, 32, 21, 56,  3, 58, 33, 33, 16, 48, 15,\n",
       "         52,  1, 24,  6, 36, 35,  3, 53,  0, 46,  7, 39, 44, 61,  6, 40, 41, 34,\n",
       "         25, 46, 26,  2,  6, 61, 64, 45,  8, 46, 49, 42,  7, 61, 28, 23, 14, 60,\n",
       "         41, 22, 29, 44,  7, 26, 33, 27, 16, 25, 37, 20, 39, 43, 30, 21, 40, 41,\n",
       "          3, 42, 63, 18,  4, 46, 53, 29, 63, 26, 41, 59, 58, 64, 64, 45, 44, 27,\n",
       "         11, 10, 30, 46, 61,  2, 39, 22,  3,  0, 46, 18, 45, 42, 54, 17, 39, 21,\n",
       "         53, 15, 49, 13, 17, 43, 30, 64, 46, 26, 49, 18, 19, 53, 10, 24, 52, 45,\n",
       "         57, 47, 55, 24, 49,  2, 28, 60, 29, 51, 14, 43, 30, 25, 37,  0,  7, 19,\n",
       "         17,  0,  8, 12, 32,  2,  2, 15, 51, 15, 14, 26,  7, 40,  0, 22, 26, 23,\n",
       "         36, 41, 16, 38, 53, 61,  2, 34, 29, 45, 64, 12, 10, 48, 45,  7, 36, 50,\n",
       "         49,  3, 58,  7, 20, 16, 63, 24,  4,  2, 44,  8,  1, 59, 16, 21, 23, 41,\n",
       "          6, 64, 55, 57, 40, 25, 16,  0, 55, 13, 15, 50, 48, 34, 64, 22, 16, 48,\n",
       "         19, 47, 45, 13, 58,  6, 34, 42, 40, 52,  1, 19, 59, 56, 21, 29, 55, 62,\n",
       "         60, 51, 27, 45, 59,  8, 47,  6, 38,  6, 58, 44, 36, 33, 25, 37, 57, 11,\n",
       "         23, 32, 23, 36, 29, 20, 13, 49,  5, 20, 51, 30, 31, 50, 60, 42, 57, 11,\n",
       "         31,  7, 40, 21, 27, 35, 10, 15, 63, 34, 47, 42, 39, 43, 30, 55, 43, 30,\n",
       "         64, 23, 57, 28,  9, 39, 38, 26, 50, 60, 29, 13, 16, 57, 28, 35, 24,  5,\n",
       "         11, 58, 52, 49, 16, 13, 54, 26, 11, 38, 43, 30, 50, 52, 60, 19, 51, 61,\n",
       "         19, 53, 61,  4,  2, 49, 13, 41, 62, 15, 55, 26, 55, 25, 46, 45, 55, 15,\n",
       "         16, 21, 17, 30, 36, 27, 11, 60, 29, 33,  8,  5,  7,  7, 44, 32, 42, 60,\n",
       "          0, 55, 47,  6,  7, 18, 26, 41,  4, 36, 55, 40, 32,  9, 14, 54, 46,  3,\n",
       "         26,  0, 48, 19, 59, 16, 61, 46, 45, 61, 54, 46, 51, 11, 61, 26,  5, 14,\n",
       "         54, 40, 41, 59, 25, 34, 30, 43, 30,  6, 50,  0, 52, 41,  5,  4, 46, 27,\n",
       "         34,  9, 19, 27, 34, 24,  8, 10, 46, 17, 63, 21, 40, 41, 42]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros((1,1), dtype=torch.long) # BxT\n",
    "x = model.generate_text(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "J.gP'SRXs;w!O'Q?T3DCQt,&zXhkDRXF3WfOK\n",
      ".'jep\n",
      "H.mCaJ&o&xi:ClUSj3VxCyzxCktRil3aoDsTIr$tUUDjCn L,XW$o\n",
      "h-afw,bcVMhN!,wzg.hkd-wPKBvcJQf-NUODMYHaeRIbc$dyF&hoQyNcutzzgfO;:Rhw!aJ$\n",
      "hFgdpEaIoCkAEeRzhNkFGo:LngsiqLk!PvQmBeRMY\n",
      "-GE\n",
      ".?T!!CmCBN-b\n",
      "JNKXcDZow!VQgz?:jg-Xlk$t-HDyL&!f. uDIKc,zqsbMD\n",
      "qACljVzJDjGigAt,Vdbn GurIQqxvmOgu.i,Z,tfXUMYs;KTKXQHAk'HmRSlvds;S-bIOW:CyVidaeRqeRzKsP3aZNlvQADsPWL';tnkDApN;ZeRlnvGmwGow&!kAcxCqNqMhgqCDIERXO;vQU.'--fTdv\n",
      "qi,-FNc&XqbT3Bph$N\n",
      "jGuDwhgwphm;wN'BpbcuMVReR,l\n",
      "nc'&hOV3GOVL.:hEyIbcd\n"
     ]
    }
   ],
   "source": [
    "print(decode(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5000\n",
    "\n",
    "m = BigramModel(vocab_size)\n",
    "optim = torch.optim.Adam(m.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 4.701707363128662\n",
      "Epoch 500, loss: 3.198807954788208\n",
      "Epoch 1000, loss: 2.7940256595611572\n",
      "Epoch 1500, loss: 2.902494430541992\n",
      "Epoch 2000, loss: 2.6032276153564453\n",
      "Epoch 2500, loss: 2.472278356552124\n",
      "Epoch 3000, loss: 2.251333713531494\n",
      "Epoch 3500, loss: 2.258505344390869\n",
      "Epoch 4000, loss: 2.4022860527038574\n",
      "Epoch 4500, loss: 2.4708480834960938\n"
     ]
    }
   ],
   "source": [
    "print_every = int(0.1 * n_epochs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    xb, yb = get_batch(train)\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    if epoch % print_every == 0:\n",
    "        print(f'Epoch {epoch}, loss: {loss.item()}')\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "By ieep the cou ad wimubirdit tat Ingo od lan lloumme ITord t:\n",
      "I f t ivill, ive GELARO, fr ord, INothe pthe myo bag t thesothe cuthar, swoungis utherat, t thincatarerber; mietaive and I he mou\n",
      "Bered, divenfathas MESe,\n",
      "Tovelewif dearo t tear or!CIXFit oantor tusisaico arde thy wirethor s thon:\n",
      "\n",
      "CHEO:\n",
      "Wis l tikingd talincareangndertothe\n",
      "ARD:\n",
      "HE:\n",
      "I fove fonty are,\n",
      "RCENGondio,\n",
      "NGRDWind har mpr\n",
      "Withe fonthan-\n",
      "I IZENERESor, f s  bor yofat\n",
      "Tirdobe ia\n",
      "\n",
      "Was Yee heyowin tr I'l bls p e ms wholit f te plld,\n"
     ]
    }
   ],
   "source": [
    "text = m.generate_text(torch.zeros((1,1), dtype=torch.long))\n",
    "decoded = decode(text[0])\n",
    "\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
